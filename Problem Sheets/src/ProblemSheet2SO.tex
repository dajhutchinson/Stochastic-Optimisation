\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in, paperwidth=8.3in, paperheight=11.7in]{geometry}
\usepackage{amsmath,amsfonts,fancyhdr,bbm}
\usepackage[section,nohyphen]{DomH}
\headertitle{Stochastic Optimisation - Problem Sheet 2}

\begin{document}

% \questionsfalse
% \answersfalse

\title{Stochastic Optimisation - Problem Sheet 2}
\author{Dom Hutchinson}
\date{\today}
\maketitle


\begin{question}{3.}

\end{question}

\begin{question}{3. (a)}
  Show that, if arm 2 is played by the above algorithm in round $s+1$ (i.e. $I(s+1)=2$) then one of the following statements must be true.
  \begin{enumerate}
    \item $\displaystyle N_2(s)<\frac{2\alpha\ln(s)}{\Delta^2}$
    \item $\displaystyle\hat\mu_{2,N_2(s)}\geq\mu_2+\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}$
  \end{enumerate}
\end{question}

\begin{answer}{3. (a)}
  \textit{This is a proof by contradiction}.
  \par Suppose $I(s+1)=2$ but that none of the statements above hold. Then
  \[\begin{array}{rrclcl}
    &\hat\mu_{2,N_2(s)}-\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}&<&\mu_2&\quad&\text{by not ii)}\\
    &&=&\mu_1-\Delta&&\text{by def. of }\Delta\\
    &&\leq&\mu_1-\sqrt{\frac{2\alpha\ln(s)}{N_2(s)}}&&\text{by not i)}\\
    \implies&\hat\mu_{2,N_2(s)}+\sqrt{\frac{2\alpha\ln(s)}{N_2(s)}}-\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}&<&\mu_1\\
    \implies&\hat\mu_{2,N_2(s)}+\left(\sqrt2-\frac1{\sqrt2}\right)\sqrt{\frac{\alpha\ln(s)}{N_2(s)}}&<&\mu_1\\
    \implies&\hat\mu_{2,N_2(s)}+\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}&<&\mu_1\\
    \implies&i_2(s)&<&\mu_1
  \end{array}\]
  This means $I(s+1)=1$, which is a contradiction. Thus at least one of i) or ii) must be true.$\proved$
\end{answer}

\begin{question}{3. (b)}
  Recall that $N_2(t)=\sum_{s=1}^t\identity\{I(S)=2\}$. For an arbitrary positive integer $u$ and any $t\in\nats$ explain why
  \[ N_2(t)\leq u+\sum_{s=u+1}^t\identity\big\{\{N_2(s-1)\geq u\}\text{ and }\{I(s)=2\}\big\} \]
\end{question}

\begin{answer}{3. (b)}
  Fix $t,u\in\nats$. We have two possibilities
  \begin{itemize}
    \item[\textit{Case 1}] $N_2(t)\leq u$ (i.e. Arm two has not been played $u$ times yet). The result trivially holds in this case.
    \item[\textit{Case 2}] $\exists\ s\in[1,t]$ such that $N(s)>u$ (i.e. Arm two has been played at least $u$ times).\\ Let $s^*$ denote the smallest such $s$. Then it must be true that $N(s^*-1)=u$ and $s^*\geq u+1$. Hence
    \[\begin{array}{rclcl}
      N(t)&=&\sum_{s=1}^{s^*-1}I(s)+\sum_{s=s^*}^tI(s)&\quad&\\
      &=&N(s^*-1)+\sum_{s=s^*}^tI(s)\underbrace{\identity\{N(s-1)\geq u\}}_\text{true for all in sum}\\
      &\leq&u+\sum_{s=u+1}^t\identity\{N(s-1)\geq u\}&&\text{ since }s^*\geq u+1
    \end{array}\]
  \end{itemize}
  Thus the result holds in all cases.$\hfill\proved$
\end{answer}

\begin{question}{3. (c)}
  Define $u=\left\lceil(2\alpha\ln(t))/\Delta^2\right\rceil$. Using the answers to parts \texttt{(a)} and \texttt{(b)}, and relevant probability inequalities, show that
  \[ \expect[N_2(t)\leq u+\sum_{s=u+1}^te^{-\alpha\ln(s)} \]
  Use this to show that $\expect[N_2(t)]\leq u+\frac1{\alpha-1}$.
\end{question}

\begin{answer}{3. (c)}
  We have
  \[ \expect[N_2(t)]\leq u+\sum_{s=u+1}^te^{-\alpha\ln(s)} \]
  Taking expectations of both sides
  \[\begin{array}{rcl}
  \expect[N_2(t)]&\leq&u+\sum_{s=u+1}^t\prob\left(\{N_2(s-1)\geq u\}\text{ and }\{I(s)=2\}\right)\\
  &\leq&u+\sum_{s=u}^{t-1}\prob\left(\{N_2(s)\geq u\}\text{ and }\{I(s+1)=2\}\right)
  \end{array}\]
  If $N_2(s)\geq u$ and $I(s+1)=2$ then
  \[ \hat\mu_{2,N_2(s)}\geq\mu_2+\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}\text{ by a)} \]
  Thus
  \[ \expect(N_2(t))\leq u+\sum_{s=u}^{t-1}\prob\left(\hat\mu_{2,N_2(s)}\geq\mu_2+\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}\right)\quad(1) \]
  Let $X_1,\dots,X_{N_2}$ be the random variables for each time arm 2 was played. Consider
  \[\begin{array}{rrclcl}
  &\prob\left(\hat\mu_{2,N_2(s)}\geq\mu_2+\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}\right)&=&\prob\left(\frac{1}{N_2}\sum_{i=1}^{N_2}X_i\geq\mu_2+\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}\right)&\quad&\\
  &&=&\prob\left(\sum_{i=1}^{N_2}(X_i-\mu_2)\geq N_2\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}\right)\\
  &&\leq&\text{exp}\left(-2\cdot N_2\cdot\frac{\alpha\ln(s)}{2N_2(s)}\right)&&\text{by Hoeffding's Ineq.}\\
  &&=&\text{exp}(-\alpha\ln(s))\\
  \implies&\expect[N_2(t)]&\leq&u+\sum_{s=u+1}^te^{-\alpha\ln(s)}&&\text{by (1)}
  \end{array}\]
  Further
  \[\begin{array}{rcl}
    \expect[N_2(t)]&\leq&u+\sum_{s=u+1}^te^{-\alpha\ln(s)}\\
    &=&u+\sum_{s=u+1}^ts^{-\alpha}\\
    &\leq&u+\int_u^\infty s^{-\alpha}ds\quad\text{since }\alpha>1\\
    &=&u+\left[\frac{s^{-\alpha+1}}{-\alpha+1}\right]_u^\infty\\
    &=&u-\frac{u^{-\alpha+1}}{-\alpha+1}\\
    &=&u+\frac{u^{-\alpha+1}}{\alpha+1}
  \end{array}\]
  By the definition of $u$, $u>1$ thus $u^{-\alpha+1}<1$ since $\alpha>1$. Giving us
  \[ \expect[N_2(t)]\leq u+\frac1{\alpha-1} \]
\end{answer}

\begin{question}{3. (d)}
  Use the answer to \texttt{(c)} to show that the regret of this algorithm is bounded above as
  \[ \mathcal{R}(T)\leq\frac{2\alpha\ln(T)}\Delta+\frac{\alpha}{\alpha-1}\Delta \]
\end{question}

\begin{answer}{3. (d)}
  \[\begin{array}{rrlcl}
  \mathcal{R}(T)&:=&\Delta\expect[N_2(t)]&\quad&\\
  &\leq&\Delta\left(u+\frac1{\alpha-1}\right)&&\text{by 3. (c)}\\
  &\leq&\Delta\left(\frac{2\alpha\ln(T)}{\Delta^2}+1+\frac1{\alpha-1}\right)&&\text{by def. of }u\\
  &=&\frac{2\alpha\ln(T)}{\Delta}+\Delta\left(1+\frac1{\alpha-1}\right)\\
  &=&\frac{2\alpha\ln(T)}{\Delta}+\frac{\Delta\alpha}{\alpha-1}
  \end{array}\]
\end{answer}

\begin{question}{4.}
  Consider a bandit with two independent Gaussian arms. Rewards on arm $i$ constitute a sequence of iid $N(\mu_i,1)$ random variables.
\end{question}

\begin{question}{4. (a)}
  Let $\hat\mu_{i,n}$ denote the sample mean reward on arm $i$ after $n$ plays of this arms. Using a resulting from Homework 1, show that
  \[ \prob\left(\hat\mu_{i,n}<\mu_i+\sqrt{\frac{\alpha\ln(t}{2n}}\right)\leq\exp\left(-\frac{\alpha\ln(t)}4\right) \]
  Express the last quantity as power of $t$.
\end{question}

\begin{answer}{4. (a)}
  Let $\hat\mu_{i,n}$ be the sample mean reward on arm $i$ after $n$ plays of that arms.
  \par From \textit{Problem Sheet 1 6b)}, for $X_i\iid\text{Normal}(\mu,\sigma^2)$ and $\gamma>\mu_i$ we have that
  \[ \prob(\hat\mu>\gamma)=\prob\left(\sum_{i=1}^n X_i>n\gamma\right)\leq\exp\left(-n\frac{(\gamma-\mu)^2}{2\sigma^2}\right) \]
  Applying this result to this scenario
  \[ \prob(\hat\mu_{i,n}>\gamma)\leq\exp\left(-n\frac{(\gamma-\mu_i)^2}2\right) \]
  By defining $\gamma=\mu_i+\sqrt{\frac{\alpha\ln(t)}{2n}}$ with $\alpha>0$.
  \par Note that $\gamma>\mu_i$ so we can use the above inequality
  \[\begin{array}{rcl}
  \prob\left(\hat\mu_{i,n}>\mu_i+\sqrt{\frac{\alpha\ln(t)}{2n}}\right)&\leq&\exp\left(-\frac{n}2\cdot\frac{\alpha\ln(t)}{2n}\right)\\
  &=&\exp\left(-\frac{\alpha\ln(t)}4\right)\\
  &=&t^{-\alpha/4}
  \end{array}\]
\end{answer}

\begin{question}{4. (b)}
  Explain in a few sentences why the same bound holds the probability of the event that $\hat\mu_{i,n}<\mu_i-\sqrt{\frac{\alpha\ln(t)}{2n}}$
\end{question}

\begin{answer}{4. (b)}
  The result from \textit{Problem Sheet 1 6b)} is derived from the Chernoff Bound for IID random variables when $\left\{\sum X_i\geq nc\right\}$ and considers $\inf_{\theta>0}e^{-n\theta c}(\expect[e^{\theta X}])^n$. The result requires $c>\mu_i$ in order to fulfil the restriction on the infinum (i.e. $\theta>0$).
  \par To derive a similar result to \textit{Question 4. (a)} for the event $\textstyle\left\{\hat\mu_{i,n}<\mu_i-\sqrt{\frac{\alpha\ln(t)}{2n}}\right\}$ we define $c=\mu_i-\sqrt{\frac{\alpha\ln(t)}{2n}}$, meaning $c<\mu_i$ and that $\theta<0$.
  \par The Chernoff Bound for this complementary event considers the infinum of the same expression, except with the restriction that $\theta<0$ (rather than $\theta>0$). Given our definition of $c$ and the resulting value of $\theta$, the same value for the infinum is found. Meaning the same bound is derived for both the event and its compliment.
\end{answer}

\begin{question}{4. (c)}
  Replicate the analysis of the UCB algorithm to obtain a regret bound of the form $\mathcal{R}(T)\leq c_1+c_2\ln(T)$ where $c_1$ and $c_2$ are constants that may depend on $\alpha,\mu_1$ and $\mu_2$. Find explicit expressions for these constants.
  \par The analysis will not work for all $\alpha>1$. You will need $\alpha$ to be bigger than some other number. Find that number.
\end{question}

\begin{answer}{4. (c)}
  Assume WLOG $\mu_1>\mu_2$ and define $\Delta=\mu_1-\mu_2$. Let $N_2(t)$ be the number of times arm 2 is played in the first $t$ steps. Define $u_t=\left\lceil\frac{2\alpha\ln(t)}{\Delta^2}\right\rceil$. We have
  \[ N_2(t)\leq u+\sum_{s=u-1}^t\identity\left(\left\{N_2(s-1)\geq u_t\right\}\text{ and }\{I(s)=j\}\right) \]
  Taking expectations of both side we get
  \[ \expect[N_2(t)]\leq u_t+\sum_{s=u_t}^{t-1}\prob\left(\{N_2(s-1)\geq u_t\}\text{ and }\{I(s)=j\}\right) \]
  By ....... % TODO
  \[\begin{array}{rcl}
    \expect[N_2(t)]&\leq&u_t+\sum_{s=u_t}^{t-1}\left[\prob\left(\hat\mu_{1,N_1(s)}\leq\mu_1-\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}\right)+\prob\left(\hat\mu_{2,N_2(s)}>\mu_2-\sqrt{\frac{\alpha\ln(s)}{2N_2(s)}}\right)\right]\\
    &\leq&u_t+\sum_{s=u_t}^{t-1}2t^{-\alpha/4}\text{ by 4. (a)}\\
    &\leq&u+int_{u_t-1}^\infty2t^{-\alpha/4}dt\\
    &=&u+2\left[\frac{t^{-\frac\alpha4+1}}{1-\frac\alpha4}\right]\limits_{u_t-1}^\infty\\
    &=&u-\frac{2(u-1)^{-\frac\alpha4+1}}{-\frac{\alpha}4+1}\\
    &\leq&u+\frac{2}{\frac\alpha4-1}\\
    &=&u+\frac8{\alpha-4}\\
    &\leq&\frac{2\alpha\ln(t)}{\Delta^2}+1+\frac8{\alpha-4}\text{ by def. of }u\\
    &=&\frac{2\alpha\ln(t)}{\Delta^2}+\frac{\alpha+4}{\alpha-4}
  \end{array}\]
  In this scenario $\mathcal{R}(T)=\Delta\expect[N_2(T)]$. Thus, using the results above
  \[ \mathcal{R}(T)\leq\frac{2\alpha\ln(T)}{\Delta}+\Delta\frac{\alpha+4}{\alpha-4} \]
  This requires $\alpha>4$.
\end{answer}

\end{document}
