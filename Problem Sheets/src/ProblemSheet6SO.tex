\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in, paperwidth=8.3in, paperheight=11.7in]{geometry}
\usepackage{amsmath,amsfonts,fancyhdr,bbm}
\usepackage[section,nohyphen]{DomH}
\headertitle{Stochastic Optimisation - Problem Sheet 6}

\begin{document}

\questionsfalse
% \answersfalse

\title{Stochastic Optimisation - Problem Sheet 6}
\author{Dom Hutchinson}
\date{\today}
\maketitle


\begin{question}{2)}
  Consider the following \textit{Employment Seeking Problem}.
  \par Define a set of $n$ different wages $\mathcal{W}:=\{w(0),\dots,w(n)\}$ where $n\geq2$ and $0=w(0)<\dots<w(n)$.
  \par At the beginning of each week, a worker is offered a job with wage $w\in\mathcal{W}$ per week. The worker can either accept or reject this job. If he rejects the offered job, the worker has to look for new employment. A job with wage $w(0)$ is interpreted as being unemployed in the week the job is offered (such a job is always assumed to be rejected by the worker).
  \par Let $X_t$ be the wage associated with the job offered at the beginning of week $t$ where $t\geq0$. Assume the following
  \begin{itemize}
    \item When $X_t\neq w(0)$ and the job offer made at the beginning of week $t$ is accepted, the worker works at wage $X_t$ during the whole week $t$ and gets income $X_t$ at the end of the this week.
    \item In a week when he is employed, the worked does not look for alternative employment.
    \item When $X_t=w(0)$ or the job offered at the beginning of week $t$ is rejected, the worker is unemployed for the whole week $t$ and gets no income in this week.
    \item If $X_t\neq w(0)$ and the worker accepts the job offer made at the beginning of week $t$, then at the beginning of week $t+1$, the worker gets the same job offer with probability $p\in(0,1)$ or the worker gets unemployed with probability $1-p$.
    \[ X_t\neq0\implies\prob(X_{t+1}=X_t)=p,\ \prob(X_{t+1}=0)=1-p \]
    \item If $X_t=w(i)$ and the worker rejects the job offered at the beginning of week $t$, then at the beginning of week $t+1$, a job with wage $w(j)$ is offered to the worker with probability $q(j|i)$ where $i,j\in[1,n]$ and $\sum_{j=0}^nq(j|i)=1$.
  \end{itemize}
  The worker's objective is to maximise the expected discounted weekly income
  \[ \expect^\pi\left(\sum_{t=0}^\infty\alpha^tR_t\right) \]
  where $R_t$ is the income in week $t$ and $\alpha\in(0,1)$ is the discounting factor.
\end{question}

\begin{question}{2) (a)}
  Formulate the described employment seeking problem as a Markov Decision Problem.
\end{question}

\begin{answer}{2) (a)}
  Here I formulate the problem described in \texttt{2)} as a discounted reward Markov decision problem over an infinite-horizon.
  \begin{itemize}
    \item \textit{Decision Epochs} - Start of each week.
    \item \textit{Epoch $t$} - The beginning of time-period $t$.
    \item \textit{Time Horizon} - $T=\{0,1,\dots\}$.
    \item \textit{System States}.
    \par Let $X_t$ be the system state at epoch $t$ defined as the wage the employ is offered in epoch $t$.
    \item \textit{State-Space} - $S=\mathcal{W}$.
    \item \textit{Agent-Actions}.
    \par Let $Y_t$ be the action taken by the employee in epoch $t$, defined to be whether the employee accepts the job or not.
    \[ Y_t=\indexed\{\text{accepts job}\} \]
    \item \textit{Action-Space} - $A=\{0,1\}$.
    \item \textit{Admissible Actions}.
    \[\begin{array}{rcl}
      A(w(0))&=&\{0\}\\
      A(s)&=&\{0,1\}\quad\forall\ s\in\mathcal{W}\setminus\{w(0)\}
    \end{array}\]
    \item \textit{Transition Probabilities}.
    \par Let $s,s'\in S,a\in A(s)$ and define $p_t(s'|s,a)=\prob(X_{t+1}=s'|X_t=s,Y_t=1)$. Consider the following two cases
    \begin{itemize}
      \item[\textit{Case 1}] The agent accepted their last job offer (ie $a=1$).
        \[\begin{array}{rcl}
          p_t(s'|s,1)&=&\begin{cases}
                          p  &\text{if }s'=s\\
                          1-p&\text{if }s'=0
                        \end{cases}
        \end{array}\]
      \item[\textit{Case 2}] The agent rejected their last job offer (ie $a=0$).
        \[ p_t(s'|s,0)=q(s'|s) \]
    \end{itemize}

    \item \textit{Equivalent Rewards}.
    \par Let $s\in S,a\in A(s)$. In each epoch the agent earns the wage they are offered $s$ if they accepted the job (ie $a=1$), otherwise they earn nothing.
    \[ r(s,a)=s\cdot a \]

    \item \textit{Equivalent Objective}.
    \par Find the policy, $\pi\in HR(T)$ which maximises the expected discounted reward
    \[ \expect^\pi\left[\sum_{t=0}^\infty\alpha^t r(X_t,Y_t)\right] \]
    where $\alpha\in(0,1)$ is the discounting factor.
  \end{itemize}
\end{answer}

\begin{question}{2) (b)}
  Consider the following setup
  \begin{itemize}
    \item $n=2,\ p=3/5, \alpha=3/4$.
    \item $w(1)=12/5,\ w(2)=16$.
    \item $q(i|j)=$\begin{tabular}{c|ccc}
        j\textbackslash i&0&1&2\\\hline
        0&1/5&1/2&3/10\\
        1&3/10&3/10&2/5\\
        2&3/10&1/2&1/5
      \end{tabular}
  \end{itemize}
  Consider a policy in which the worker always accepts a job with a strictly positive wage. Is this policy optimal?
\end{question}

\begin{answer}{2) (b)}
  From the specification of the question we know the following
  \[\begin{array}{rcl}
    \mathcal{W}&=&\{w(0),w(1),w(2)\}\\
    &=&\{0,12/5,16\}\\
    S&=&\{0,12/5,16\}\\
    A(0)&=&\{0\}\\
    A(12/5)&=&\{0,1\}\\
    A(16)&=&\{0,1\}\\
    P&=&\begin{pmatrix}
          0.2&0.5&0.3\\
          0.3&0.3&0.4\\
          0.3&0.5&0.2
        \end{pmatrix}
  \end{array}\]
  Consider a policy $\pi$ st $Y_t=1$ if $X_t>0$ and $Y_t=0$ if $X_t=0$.
  \par Here I shall use the \textit{Policy Iteration Algorithm} to determine whether this policy $\pi$ is optimal. $\pi$ is optimal if the algorithm does not suggest a different policy after one iteration.
  \par Define the following
  \[\begin{array}{rcl}
    w_{k+1}(s,a)&=&r(s,a)+\alpha\sum_{s'\in S}v_k(s')p(s'|s,a)\\
    d_{k+1}(s)&\in&\argmax_{a\in A(s)}w_{k+1}(s,a)
  \end{array}\]
  Using the policy $\pi$, I initialise the algorithm as follows
  \[ d_0(w_0)=0\quad d_0(w_1)=1 \quad d_0(w_2)=1 \]
  Note that $d_0(s)$ can be any Markovian decision function which satisfies $d_0(s)\in A(s)\ \forall\ s\in S$.
  \par Consider an iteration of the algorithm where $k=0$. We want to compute a solution $v_0(s)$ for the following
  \[\begin{array}{rcl}
    v(s)&=&(T_{d_0}v)(s)\\
    &=&r(s,d_0(s))+\alpha\sum_{s'\in S}v(s')p(s'|s,d_0(s))
  \end{array}\]
  This can be expanded to the following system of three equations
  \[\begin{array}{rcl}
    v(w_0)&=&\frac34\left(\frac{v(w_0)}5+\frac{v(w_1)}2+\frac{3v(w_2)}{10}\right)\\
    &=&\frac3{20}v(w_0)+\frac{3}{8}v(w_0)+\frac{9}{40}v(w_2)\\
    v(w_1)&=&\frac{12}5+\frac34\left(\frac{3v(w_0)}{10}+\frac{3v(w_1)}{10}+\frac{2v(w_2)}5\right)\\
    &=&\frac{12}5+\frac{9}{40}v(w_0)+\frac{9}{40}v(w_1)+\frac{3}{10}v(w_2)\\
    v(w_2)&=&16+\frac34\left(\frac{3v(w_0)}{10}+\frac{v(w_1)}{2}+\frac{v(w_2)}5\right)\\
    &=&16+\frac{9}{40}v(w_0)+\frac{3}{8}v(w_1)+\frac{3}{20}v(w_2)\\
  \end{array}\]
  I CANT BE ASKED TO SOLVE THIS
\end{answer}

\begin{question}{3)}
  Consider the following \textit{management/advertising problem}.
  \par A company makes products of the same type. The monthly sales of these products fluctuate about values $b(1),\dots,b(n)$ where $n\geq2$ where $0<b(1)<\dots<b(n)$.
  \par The sales mainly depend on the company's marketing strategy.
  \par At the beginning of each month, the company knows what the sales in the previous month were and selects its marketing strategy for the current month. The company can choose one of $m$ strategies, where $m\geq2$.
  \par The available strategies are labelled by integers $1,\dots,m$. The cost of strategy $k$ is $c(k)$ where $0<c(1)<\dots<c(m)$.
  If strategy $k$ is applied during the current month, and if $b(i)$ is the number of sales in the previous month, then the sale in the current month will be $b(j)$ with probability $p(j|i,k)$ where $\sum_{j=1}^np(j|i,j)=1$ for each $i\in[1,n],k\in[1,m]$.
  \par The company wants to select a marketing policy such that the corresponding expected discounted income is maximal. More specifically, at the beginning of each month, the company wants to choose a marketing strategy such that the expected discounted income
  \[ \expect^\pi\left(\sum_{t=0}^\infty\alpha^tR_t\right) \]
  attains its maximum value. Here, $R_t$ is the company's income in month $t$, while $\alpha\in(0,1)$ is the discounting factor.
\end{question}

\begin{question}{3) (a)}
  Formulate the described production management problem as a finite horizon Markov decision problem. More precisely, state the state-space $S$, action-space $A$, time-horizon $T$, transition probabilities $p_t(s'|s,a)$ and immediate rewards $r_t(s,a)$.
\end{question}

\begin{answer}{3) (a)}
  Here I formulate the problem described in \texttt{3)} as a discounted reward Markov decision problem over a finite-horizon.
  \begin{itemize}
    \item \textit{Decision Epochs} - Start of each month.
    \item \textit{Epoch $t$} - Start of time-period $t$.
    \item \textit{Time Horizon} - $T=\{0,1,\dots,N\}$
    \item \textit{System States}.
    \par Let $X_t$ be the system state at epoch $t$, defined as the number of sales in the previous month.
    \item \textit{State-Space} - $S=\{b(1),\dots,b(n)\}$
    \item \textit{Agent-Actions}.
    \par Let $Y_t$ be the action taken by the company in epoch $t$, defined as the strategy the company chooses to use.
    \item \textit{Action-Space} - $A=\{1,\dots,m\}$
    \item \textit{Admissible Actions} - $A(s)=S\ \forall\ s\in S$.
    \item \textit{Transition Probabilities} - $\prob(X_{t+1}=s'|X_t=s,Y_t=a)=p(s'|s,a)$ as defined in question.
    \item \textit{Equivalent Rewards}.
    \par In each epoch the companies earns from sale $X_t$ but has to pay for its marketing campaign $c(Y_t)$.
    \[ r(s,a)=s-c(a) \]
    \item \textit{Equivalent Objective}.
    \par Find the policy $\pi\in HR(T)$ which maximises the expected discounted reward
    \[ \expect^\pi\left[\sum_{t=0}^N\alpha^tr(X_t,Y_t)\right] \]
    where $\alpha\in(0,1)$ is the discounting factor.
  \end{itemize}
\end{answer}

\begin{question}{3)(b)}
  Consider the following setup
  \begin{itemize}
    \item $\alpha=1/2,n=2,m=2$.
    \item $b(1)=2,b(2)=8$.
    \item $c(1)=1,c(2)=5$.
    \item $p(2|1,1)=1/5,p(2|2,1)=3/10$.
    \item $p(2|1,2)=3/5,p(2|2,2)=4/5$.
  \end{itemize}
  Using the policy iteration method, find an optimal policy for the Markov decision problem formulated in $(a)$.
\end{question}

\begin{answer}{3)(b)}
  From the specification of the question we know the following
  \[\begin{array}{rcl}
    T&=&\{0,\dots,N\}\\
    S&=&\{b_1,b_2\}=\{2,8\}\\
    A&=&\{1,2\}\\
    A(s)&=&\{1,2\}\ \forall\ s\in S\\
    p(s'|s,1)&=&\begin{tabular}{c|cc}
                  s'\setminus s&b_1&b_2\\\hline
                  b_1&.8&.7\\
                  b_2&.2&.3
                \end{tabular}\\\\
    p(s'|s,2)&=&\begin{tabular}{c|cc}
                  s'\setminus s&b_1&b_2\\\hline
                  b_1&.4&.2\\
                  b_2&.6&.8
                \end{tabular}
  \end{array}\]
  I shall now implement the \textit{Policy Iteration Algorithm} in order to find an optimal policy from this specification of the problem in \texttt{3) (a)}.
  \par \underline{Initialisation} - Let $k=0$ and define $d_0(b_1=2,d_0(b_2)=2$.
  \par \underline{Iteration 1} - $k=1$
  \par \textit{Policy Evaluation} - I shall compute a solution $v_0(s)$ for the following equation
  \[\begin{array}{rcl}
    v(s)&=&(T_{d_0}v)(s)\\
    &=&r(s,d_0(s))+\alpha\sum_{s'\in S}v(s')p(s'|s,d_0(s))
  \end{array}\]
  This can be expanded to the following series of equations
  \[\begin{array}{rcl}
    v(b_1)&=&r(b_1,2)+\frac12\big[v(b_1)p(b_1|b_1,d_0(b_1))+v(b_2)p(b_2|b_1,d_0(b_1))\big]\\
    &=&r(b_1,2)+\frac12\big[v(b_1)p(b_1|b_1,2)+v(b_2)p(b_2|b_1,2)\big]\\
    &=&(b_1-c(2))+\frac12\left[v(b_1)\cdot\frac25+v(b_2)\frac35\right]\\
    &=&-3+v(b_1)\cdot\frac1{5}+v(b_2)\frac3{10}\\

    v(b_2)&=&r(b_2,2)+\frac12\big[v(b_1)p(b_1|b_2,d_0(b_2))+v(b_2)p(b_2|b_2,d_0(b_2))\big]\\
    &=&r(b_2,2)+\frac12\big[v(b_1)p(b_1|b_2,2)+v(b_2)p(b_2|b_2,2)\big]\\
    &=&(b_2-c(2))+\frac12\left[v(b_1)\cdot\frac15+v(b_2)\cdot\frac45\right]\\
    &=&3+v(b_1)\frac1{10}+v(b_2)\frac2{5}
  \end{array}\]
  A solution to this is
  \[ v_0(b_1)=-2\quad v_0(b_2)=\frac{14}3 \]
  \textit{Policy Improvement} - I shall compute $d_1(s)$ using the following system of equations
  \[\begin{array}{rcl}
    w_1(s,a)&=&r(s,a)+\alpha\sum_{s'\in S}v_0(s')p(s'|s,a)\\
    d_1(s)&\in&\argmax_{a\in A(s)}w_1(s,a)
  \end{array}\]
  The tables below summarise the values for these equations
  \begin{center}
    \begin{array}{rcl}
      $w_1(s,a)$&=&\begin{tabular}{c|cc}
        $s$\textbackslash$a$&1&2\\\hline
        $b_1$&2/3&-2\\
        $b_2$&7&14/3
      \end{tabular}\\\\
      $d_1(s)$&=&\begin{tabular}{c|ccc}
        $s$&$d_1(s)$\\\hline
        $b_1$&1\\
        $b_2$&1
      \end{tabular}
    \end{array}
  \end{center}
  $d_0(s)\neq d_1(s)$ so I perform another iteration of the algorithm.
  \par \underline{Iteration 2} - $k=2$
  \par \textit{Policy Evaluation} - I shall compute a solution $v_1(s)$ for the following system of equations
  \[\begin{array}{rcl}
    v(b_1)&=&r(b_1,1)+\frac12\big[v(b_1)p(b_1|b_1,d_1(b_1))+v(b_2)p(b_2|b_1,d_1(b_1))\big]\\
    &=&r(b_1,1)+\frac12\big[v(b_1)p(b_1|b_1,1)+v(b_2)p(b_2|b_1,1)\big]\\
    &=&(2-1)+\frac12\left[v(b_1)\frac45+v(b_2)\frac15\right]\\
    &=&1+v(b_1)\frac25+v(b_2)\frac1{10}\\

    v(b_2)&=&r(b_2,1)+\frac12\big[v(b_1)p(b_1|b_2,d_1(b_2))+v(b_2)p(b_2|b_2,d_1(b_2))\big]\\
    &=&r(b_2,1)+\frac12\big[v(b_1)p(b_1|b_2,1)+v(b_2)p(b_2|b_2,1)\big]\\
    &=&(8-1)+\frac12\left[v(b_1)\frac7{10}+v(b_2)\frac3{10}\right]\\
    &=&7+v(b_1)\frac7{20}+v(b_2)\frac3{20}
  \end{array}\]
  A solution to this is
  \[ v_1(b_1)=\frac{69}{44}\quad v_1(b_2)=\frac{245}{22} \]
  \textit{Policy Improvement} - I shall compute $d_2(s)$ using the following system of equations
  \[\begin{array}{rcl}
    w_2(s,a)&=&r(s,a)+\alpha\sum_{s'\in S}v_1(s')p(s'|s,a)\\
    d_2(s)&\in&\argmax_{a\in A(s)}w_2(s,a)
  \end{array}\]
  The tables below summarise the values for these equations
  \begin{center}
    \begin{array}{rcl}
      $w_2(s,a)$&=&\begin{tabular}{c|cc}
        $s$\textbackslash$a$&1&2\\\hline
        $b_1$&600/220&36/55\\
        $b_2$&8113/880&6698/880
      \end{tabular}\\\\
      $d_2(s)$&=&\begin{tabular}{c|ccc}
        $s$&$d_1(s)$\\\hline
        $b_1$&1\\
        $b_2$&1
      \end{tabular}
    \end{array}
  \end{center}
  $d_1(s)=d_2(s)\ \forall\ s\in S$. Thus the algorithm terminates and our optimal policy is
  \[ d(b_1)=1\quad d(b_2)=1 \]
\end{answer}

\end{document}
